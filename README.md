# Parameter-tuning-and-Cross-validation-with-different-classifiers
In order to compare the performance of multiple machine learners, meaningful numeric measures of performance must be chosen. In this case, a performance measure is any way of assigning a number to measure how well a classifier’s predicted classes for the test set.Another consideration for establishing the performance of a given learner on a given dataset is how to partition the set into training and testing sets. When preforming a single trial with one train/test partition, the learner’s performance may be sensitive to the chosen partition match up with the ground-truth classes. A better way to handle this is the k-fold cross-validation
